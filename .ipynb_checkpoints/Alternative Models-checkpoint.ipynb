{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Models\n",
    "In order to ensure the model used to make predictions for the analysis, I also tried training & testing various other models that were good candidates (based on the characteristics of our data).\n",
    "\n",
    "Specifically, we also tested the following regression models:\n",
    "1. Linear (Lasso Regularization)\n",
    "2. Linear (Ridge Regularization)\n",
    "3. SGD\n",
    "4. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>guests_included</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>maximum_nights</th>\n",
       "      <th>review_scores_rating</th>\n",
       "      <th>...</th>\n",
       "      <th>property_type_Townhouse</th>\n",
       "      <th>property_type_Treehouse</th>\n",
       "      <th>property_type_Villa</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "      <th>bed_type_Couch</th>\n",
       "      <th>bed_type_Futon</th>\n",
       "      <th>bed_type_Pull-out Sofa</th>\n",
       "      <th>bed_type_Real Bed</th>\n",
       "      <th>annual_booked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1125</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>93.939368</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>730</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>104.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 284 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_total_listings_count  accommodates  bathrooms  \\\n",
       "0                0.0                        6.0             2        1.0   \n",
       "1                0.0                        5.0             2        1.0   \n",
       "2                0.0                        1.0             2        1.0   \n",
       "3                0.0                        1.0             3        1.0   \n",
       "4                0.0                        1.0             2        1.0   \n",
       "\n",
       "   bedrooms  beds  guests_included  minimum_nights  maximum_nights  \\\n",
       "0       1.0   1.0                1               1             730   \n",
       "1       0.0   1.0                2               1            1125   \n",
       "2       1.0   1.0                2               3               7   \n",
       "3       1.0   4.0                1               1             730   \n",
       "4       1.0   2.0                1               4              90   \n",
       "\n",
       "   review_scores_rating  ...  property_type_Townhouse  \\\n",
       "0             98.000000  ...                        0   \n",
       "1             95.000000  ...                        0   \n",
       "2             93.939368  ...                        0   \n",
       "3             90.000000  ...                        0   \n",
       "4             89.000000  ...                        0   \n",
       "\n",
       "   property_type_Treehouse  property_type_Villa  room_type_Private room  \\\n",
       "0                        0                    0                       1   \n",
       "1                        0                    0                       0   \n",
       "2                        0                    0                       1   \n",
       "3                        0                    0                       0   \n",
       "4                        0                    0                       0   \n",
       "\n",
       "   room_type_Shared room  bed_type_Couch  bed_type_Futon  \\\n",
       "0                      0               0               0   \n",
       "1                      0               0               0   \n",
       "2                      0               0               0   \n",
       "3                      0               0               0   \n",
       "4                      0               0               0   \n",
       "\n",
       "   bed_type_Pull-out Sofa  bed_type_Real Bed  annual_booked  \n",
       "0                       0                  1            5.0  \n",
       "1                       0                  1           81.0  \n",
       "2                       1                  0            0.0  \n",
       "3                       0                  1          299.0  \n",
       "4                       0                  1          104.0  \n",
       "\n",
       "[5 rows x 284 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Import & preview input variables\n",
    "X = pd.read_csv('./output/model_X.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     2.041096\n",
       "1    49.931507\n",
       "2     0.000000\n",
       "3    72.906849\n",
       "4    29.917808\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input & preview output variables\n",
    "y = pd.read_csv('./output/model_y.csv', header=None, squeeze=True)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear (Lasso Regularization)\n",
    "We're going to first try the simplest of the list by adding _Lasso regularization_ to the Linear Regression. The hope is that with the corrective properties (by penalizing complexity), we will be able to get substantially higher training & testing scores.\n",
    "\n",
    "We're going to test the Lasso model with various alpha values to spot the config with optimal scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (1.0):\n",
      "0.23223211976073035\n",
      "0.18862779654313222\n",
      "-------\n",
      "Coefficients Used:\n",
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0, 0.23223211976073035, 0.18862779654313222, 20)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to run Lasso model\n",
    "\n",
    "def runLasso(alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute the training & testing scores of the Linear Regression (with Lasso regularization)\n",
    "    along with the SUM of coefficients used.\n",
    "    \n",
    "    Input:\n",
    "        alpha: the degree of penalization for model complexity\n",
    "        \n",
    "    Output:\n",
    "        alpha: the degree of penalization for model complexity\n",
    "        train_scoreL: Training score\n",
    "        test_scoreL: Testing score\n",
    "        coeff_used: SUM of all coefficients used in model\n",
    "    \"\"\"\n",
    "    \n",
    "    # Instantiate & train\n",
    "    lasso_reg = Lasso(alpha=alpha)\n",
    "    lasso_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict testing data\n",
    "    pred_train = lasso_reg.predict(X_train)\n",
    "    pred_test = lasso_reg.predict(X_test)\n",
    "\n",
    "    # Score\n",
    "    train_scoreL = lasso_reg.score(X_train,y_train)\n",
    "    test_scoreL = lasso_reg.score(X_test,y_test)\n",
    "    coeff_used = np.sum(lasso_reg.coef_!=0)\n",
    "    \n",
    "    print(\"Lasso Score (\" + str(alpha) + \"):\")\n",
    "    print(train_scoreL)\n",
    "    print(test_scoreL)\n",
    "    print(' ')\n",
    "    print(\"Coefficients Used:\")\n",
    "    print(coeff_used)\n",
    "    print('-------')\n",
    "    \n",
    "    return (alpha, train_scoreL, test_scoreL, coeff_used)\n",
    "\n",
    "runLasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (1e-15):\n",
      "0.2559366327386795\n",
      "0.20189974847694037\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (1e-10):\n",
      "0.2559366327390432\n",
      "0.20189974871655747\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (1e-08):\n",
      "0.2559366327750352\n",
      "0.20189977241934653\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (0.0001):\n",
      "0.25593536548472673\n",
      "0.2019226658696961\n",
      "-------\n",
      "Coefficients Used:\n",
      "276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Score (0.001):\n",
      "0.25587513878367596\n",
      "0.20203614035738615\n",
      "-------\n",
      "Coefficients Used:\n",
      "241\n",
      "Lasso Score (0.01):\n",
      "0.25495352910683877\n",
      "0.20238889968783336\n",
      "-------\n",
      "Coefficients Used:\n",
      "124\n",
      "Lasso Score (1):\n",
      "0.23223211976073035\n",
      "0.18862779654313222\n",
      "-------\n",
      "Coefficients Used:\n",
      "20\n",
      "Lasso Score (5):\n",
      "0.20547594338644537\n",
      "0.16504046703963937\n",
      "-------\n",
      "Coefficients Used:\n",
      "12\n",
      "Lasso Score (10):\n",
      "0.19236671314805076\n",
      "0.15451447757549708\n",
      "-------\n",
      "Coefficients Used:\n",
      "8\n",
      "Lasso Score (20):\n",
      "0.18615436751503778\n",
      "0.14947038592763684\n",
      "-------\n",
      "Coefficients Used:\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# Test the Lasso regularization for a range of alpha variables\n",
    "\n",
    "alpha_lasso = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "\n",
    "for i in range(10):\n",
    "    runLasso(alpha_lasso[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Lasso) Conclusion\n",
    "\n",
    "The Lasso linear model does not seem to surpass the simple Linear Regression model trained (see \"Airbnb NYC Data Exploration\" notebook for details), which had scored 25.6% (training) and 20.2% (testing).\n",
    "\n",
    "**Therefore, we will discount this as a superior modelling assumption**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear (Ridge Regularization)\n",
    "Similarly, we're going to test a Linear Regression with _Ridge regularization_. Since the dataset is non-sparse, the hypothesis is that we should get more from the L2 regularization's corrective properties for complexity (more than Lasso's L1 reg.)\n",
    "\n",
    "We're going to test the Ridge model with various alpha values to spot the config with optimal scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Score (1.0):\n",
      "0.20902323915862486\n",
      "0.16550505004900973\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "# Function to run Ridge model\n",
    "\n",
    "def runRidge(alpha=1.0):\n",
    "    \"\"\"\n",
    "    Compute the training & testing scores of the Linear Regression (with Ridge regularization)\n",
    "    along with the SUM of coefficients used.\n",
    "    \n",
    "    Input:\n",
    "        alpha: the degree of penalization for model complexity\n",
    "        \n",
    "    Output:\n",
    "        alpha: the degree of penalization for model complexity\n",
    "        train_scoreL: Training score\n",
    "        test_scoreL: Testing score\n",
    "        coeff_used: SUM of all coefficients used in model\n",
    "    \"\"\"\n",
    "    # Instantiate & train\n",
    "    rid_reg = Ridge(alpha=alpha, normalize=True)\n",
    "    rid_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict testing data\n",
    "    pred_train = rid_reg.predict(X_train)\n",
    "    pred_test = rid_reg.predict(X_test)\n",
    "\n",
    "    # Score\n",
    "    train_score = rid_reg.score(X_train,y_train)\n",
    "    test_score = rid_reg.score(X_test,y_test)\n",
    "    coeff_used = np.sum(rid_reg.coef_!=0)\n",
    "    \n",
    "    print(\"Ridge Score (\" + str(alpha) + \"):\")\n",
    "    print(train_score)\n",
    "    print(test_score)\n",
    "    print('-------')\n",
    "    print(\"Coefficients Used:\")\n",
    "    print(coeff_used)\n",
    "    \n",
    "    return (alpha, train_score, test_score, coeff_used)\n",
    "\n",
    "runRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.44717e-17): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Score (1e-15):\n",
      "0.2559366870637817\n",
      "0.20189484648856693\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (1e-10):\n",
      "0.2559366870637817\n",
      "0.20190767294147383\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (1e-08):\n",
      "0.2559366870637807\n",
      "0.20190767275041943\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (0.0001):\n",
      "0.25593659625822296\n",
      "0.20190549320829965\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (0.001):\n",
      "0.2559322297145006\n",
      "0.20188920584965975\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (0.01):\n",
      "0.255889202023326\n",
      "0.20184044553149974\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (1):\n",
      "0.20902323915862486\n",
      "0.16550505004900973\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (5):\n",
      "0.11072430763295538\n",
      "0.08812228834875402\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (10):\n",
      "0.0704876562860427\n",
      "0.05617677247752917\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n",
      "Ridge Score (20):\n",
      "0.040971903570563684\n",
      "0.0326704448518893\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "alpha_ridge = [1e-15, 1e-10, 1e-8, 1e-4, 1e-3,1e-2, 1, 5, 10, 20]\n",
    "\n",
    "for i in range(10):\n",
    "    runRidge(alpha_ridge[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression (Ridge) Conclusion\n",
    "\n",
    "The Ridge linear model also does not seem to surpass the simple Linear Regression model (see \"Airbnb NYC Data Exploration\" notebook for details), which had scored 25.6% (training) and 20.2% (testing).\n",
    "\n",
    "**Therefore, we will discount Ridge regularization as a superior modelling assumption**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent (SGD) Regression\n",
    "The SGD regression is different from the former two (Lasso, Ridge) that were based on a Linear Regression model. Since SGD basically applies the squared trick at every point in our data at same time (vs Batch, which looks at points one-by-one), I don't expect scores to differ too much when compared to the previous 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nickb\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Score:\n",
      "-8.783751868376809e+45\n",
      "-3.2951885575502357e+37\n",
      "-------\n",
      "Coefficients Used:\n",
      "279\n"
     ]
    }
   ],
   "source": [
    "# Function to run SGD model\n",
    "\n",
    "def runSGD():\n",
    "    \"\"\"\n",
    "    Compute the training & testing scores of the SGD\n",
    "    along with the SUM of coefficients used.\n",
    "        \n",
    "    Output:\n",
    "        train_score: Training score\n",
    "        test_score: Testing score\n",
    "        coeff_used: SUM of all coefficients used in model\n",
    "    \"\"\"\n",
    "    # Instantiate & train\n",
    "    sgd_reg = SGDRegressor(loss=\"squared_loss\", penalty=None)\n",
    "    sgd_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict testing data\n",
    "    pred_train = sgd_reg.predict(X_train)\n",
    "    pred_test = sgd_reg.predict(X_test)\n",
    "\n",
    "    # Score\n",
    "    train_score = sgd_reg.score(X_train,y_train)\n",
    "    test_score = sgd_reg.score(X_test,y_test)\n",
    "    coeff_used = np.sum(sgd_reg.coef_!=0)\n",
    "    \n",
    "    print(\"SGD Score:\")\n",
    "    print(train_score)\n",
    "    print(test_score)\n",
    "    print('-------')\n",
    "    print(\"Coefficients Used:\")\n",
    "    print(coeff_used)\n",
    "    \n",
    "    return (train_score, test_score, coeff_used)\n",
    "\n",
    "runSGD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent (SGD) Conclusion\n",
    "\n",
    "The SGD model also does not seem to surpass the simple Linear Regression model (see \"Airbnb NYC Data Exploration\" notebook for details), which had scored 25.6% (training) and 20.2% (testing). In fact, the output training & testing scores are negative, indicative of terrible fit to the data.\n",
    "\n",
    "**Therefore, we will discount SGD as a superior modelling assumption**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "Unlike the former models, Decision Trees have a very different model structure. That is, it generates a series of nodes & branches that maximize informtion gain. Thus, it naturally is also the model most prone to overfitting\n",
    "\n",
    "To remedy the overfitting challenge, we'll run the Decision Trees model with the below parameters:\n",
    "- max_depth\n",
    "- min_samples_leaf\n",
    "- min_samples_split\n",
    "\n",
    "To isolate the effect of these parameters on scores, we'll change one at a time (i.e. keeping other parameters constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score (None, 1, 2):\n",
      "0.9878965346502062\n",
      "-0.03756831319523579\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "# Function to run Decision Trees\n",
    "def runTree(max_depth=None, min_samples_leaf=1, min_samples_split=2):\n",
    "    \"\"\"\n",
    "    Compute the training & testing scores of the Linear Regression (with Lasso regularization)\n",
    "    along with the SUM of coefficients used.\n",
    "    \n",
    "    Input:\n",
    "        max_depth: maximum allowed depth of trees (\"distance\" between root & leaf)\n",
    "        min_samples_leaf: minimum samples to contain per leaf\n",
    "        min_samples_split: minimum samples to split a node\n",
    "        \n",
    "    Output:\n",
    "        max_depth: maximum allowed depth of trees (\"distance\" between root & leaf)\n",
    "        min_samples_leaf: minimum samples to contain per leaf\n",
    "        min_samples_split: minimum samples to split a node\n",
    "        train_score: Training score\n",
    "        test_score: Testing score\n",
    "    \"\"\"\n",
    "    # Instantiate & train\n",
    "    tree_reg = DecisionTreeRegressor(criterion='mse', max_depth=max_depth, min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split)\n",
    "    tree_reg.fit(X_train, y_train)\n",
    "\n",
    "    # Predict testing data\n",
    "    pred_train = tree_reg.predict(X_train)\n",
    "    pred_test = tree_reg.predict(X_test)\n",
    "\n",
    "    # Score\n",
    "    train_score = tree_reg.score(X_train,y_train)\n",
    "    test_score = tree_reg.score(X_test,y_test)\n",
    "    \n",
    "    print(\"Tree Score (\" + str(max_depth) + ', ' + str(min_samples_leaf) + ', ' + str(min_samples_split) + \"):\")\n",
    "    print(train_score)\n",
    "    print(test_score)\n",
    "    print('-------')\n",
    "\n",
    "runTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score (2, 1, 2):\n",
      "0.15479934586567123\n",
      "0.12183263202028384\n",
      "-------\n",
      "Tree Score (5, 1, 2):\n",
      "0.4744294887573631\n",
      "0.07241405400320378\n",
      "-------\n",
      "Tree Score (6, 1, 2):\n",
      "0.525310295933926\n",
      "0.08305001615068186\n",
      "-------\n",
      "Tree Score (7, 1, 2):\n",
      "0.5638299452344031\n",
      "0.07131265727236702\n",
      "-------\n",
      "Tree Score (8, 1, 2):\n",
      "0.6307552187994618\n",
      "-0.028863898962306234\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "depths = [2, 5, 6, 7, 8]\n",
    "for dep in depths:\n",
    "    runTree(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score (7, 2, 2):\n",
      "0.44084600423305964\n",
      "0.14480057994068019\n",
      "-------\n",
      "Tree Score (7, 4, 2):\n",
      "0.3857547145581244\n",
      "0.17718732285841887\n",
      "-------\n",
      "Tree Score (7, 6, 2):\n",
      "0.3421063058328305\n",
      "0.19366673593944272\n",
      "-------\n",
      "Tree Score (7, 8, 2):\n",
      "0.33583295299107185\n",
      "0.1936338179864181\n",
      "-------\n",
      "Tree Score (7, 10, 2):\n",
      "0.3438241646559581\n",
      "0.20280465059455732\n",
      "-------\n",
      "Tree Score (7, 12, 2):\n",
      "0.32942818941899776\n",
      "0.2207759709711551\n",
      "-------\n",
      "Tree Score (7, 14, 2):\n",
      "0.3283815370863621\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 16, 2):\n",
      "0.32610147391348787\n",
      "0.22092665015994173\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "min_leafs = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "for lfs in min_leafs:\n",
    "    runTree(7, lfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score (7, 14, 2):\n",
      "0.3283815370863621\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 14, 4):\n",
      "0.3283815370863621\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 14, 6):\n",
      "0.328381537086362\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 14, 8):\n",
      "0.328381537086362\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 14, 10):\n",
      "0.328381537086362\n",
      "0.22152969537300318\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "min_splits = [2, 4, 6, 8, 10]\n",
    "for splt in min_splits:\n",
    "    runTree(7, 14, splt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Score (2, 2, 2):\n",
      "0.15479934586567123\n",
      "0.12183263202028359\n",
      "-------\n",
      "Tree Score (2, 4, 2):\n",
      "0.15479934586567123\n",
      "0.1218326320202835\n",
      "-------\n",
      "Tree Score (2, 6, 2):\n",
      "0.15479934586567123\n",
      "0.12183263202028384\n",
      "-------\n",
      "Tree Score (2, 8, 2):\n",
      "0.15479934586567112\n",
      "0.12183263202028384\n",
      "-------\n",
      "Tree Score (2, 10, 2):\n",
      "0.15479934586567112\n",
      "0.12183263202028384\n",
      "-------\n",
      "Tree Score (2, 12, 2):\n",
      "0.15479934586567123\n",
      "0.12183263202028384\n",
      "-------\n",
      "Tree Score (2, 14, 2):\n",
      "0.15479934586567123\n",
      "0.12183263202028359\n",
      "-------\n",
      "Tree Score (2, 16, 2):\n",
      "0.15479934586567112\n",
      "0.12183263202028359\n",
      "-------\n",
      "Tree Score (5, 2, 2):\n",
      "0.36661942537925574\n",
      "0.12127467104405443\n",
      "-------\n",
      "Tree Score (5, 4, 2):\n",
      "0.31980895350015925\n",
      "0.17135495073230267\n",
      "-------\n",
      "Tree Score (5, 6, 2):\n",
      "0.2850110739746403\n",
      "0.1735525930023777\n",
      "-------\n",
      "Tree Score (5, 8, 2):\n",
      "0.2832835369825508\n",
      "0.17283090183811545\n",
      "-------\n",
      "Tree Score (5, 10, 2):\n",
      "0.2863249780699517\n",
      "0.1918975165540071\n",
      "-------\n",
      "Tree Score (5, 12, 2):\n",
      "0.2762523394476941\n",
      "0.20328371328514327\n",
      "-------\n",
      "Tree Score (5, 14, 2):\n",
      "0.2755315975582452\n",
      "0.2033077111344189\n",
      "-------\n",
      "Tree Score (5, 16, 2):\n",
      "0.27486303760327124\n",
      "0.20271830667677737\n",
      "-------\n",
      "Tree Score (6, 2, 2):\n",
      "0.4031057301801336\n",
      "0.14525767543167112\n",
      "-------\n",
      "Tree Score (6, 4, 2):\n",
      "0.35874655817501966\n",
      "0.1750417434595224\n",
      "-------\n",
      "Tree Score (6, 6, 2):\n",
      "0.31860507470410704\n",
      "0.18058329890651925\n",
      "-------\n",
      "Tree Score (6, 8, 2):\n",
      "0.31286972678471947\n",
      "0.18165469228793585\n",
      "-------\n",
      "Tree Score (6, 10, 2):\n",
      "0.3172743544799881\n",
      "0.18727097241416502\n",
      "-------\n",
      "Tree Score (6, 12, 2):\n",
      "0.30583237238819705\n",
      "0.2155639328033837\n",
      "-------\n",
      "Tree Score (6, 14, 2):\n",
      "0.3051101610205762\n",
      "0.2157563950902407\n",
      "-------\n",
      "Tree Score (6, 16, 2):\n",
      "0.3036900879498208\n",
      "0.21572479345817008\n",
      "-------\n",
      "Tree Score (7, 2, 2):\n",
      "0.44084600423305964\n",
      "0.13652250774092\n",
      "-------\n",
      "Tree Score (7, 4, 2):\n",
      "0.38575471455812427\n",
      "0.17717393832354023\n",
      "-------\n",
      "Tree Score (7, 6, 2):\n",
      "0.3421063058328304\n",
      "0.19366673593944272\n",
      "-------\n",
      "Tree Score (7, 8, 2):\n",
      "0.33583295299107185\n",
      "0.1936338179864182\n",
      "-------\n",
      "Tree Score (7, 10, 2):\n",
      "0.3438241646559581\n",
      "0.20280465059455755\n",
      "-------\n",
      "Tree Score (7, 12, 2):\n",
      "0.32942818941899776\n",
      "0.2207759709711551\n",
      "-------\n",
      "Tree Score (7, 14, 2):\n",
      "0.3283815370863621\n",
      "0.22152969537300318\n",
      "-------\n",
      "Tree Score (7, 16, 2):\n",
      "0.32610147391348787\n",
      "0.22092665015994173\n",
      "-------\n",
      "Tree Score (8, 2, 2):\n",
      "0.49318309103880276\n",
      "0.13213326838233808\n",
      "-------\n",
      "Tree Score (8, 4, 2):\n",
      "0.43364663739845166\n",
      "0.17776572439907823\n",
      "-------\n",
      "Tree Score (8, 6, 2):\n",
      "0.38399253131822564\n",
      "0.17847242660476448\n",
      "-------\n",
      "Tree Score (8, 8, 2):\n",
      "0.36924288428982077\n",
      "0.19076914083791197\n",
      "-------\n",
      "Tree Score (8, 10, 2):\n",
      "0.37512911352610356\n",
      "0.20244446715501105\n",
      "-------\n",
      "Tree Score (8, 12, 2):\n",
      "0.3550419141501441\n",
      "0.22020966012959908\n",
      "-------\n",
      "Tree Score (8, 14, 2):\n",
      "0.3523734735488766\n",
      "0.2221020833501406\n",
      "-------\n",
      "Tree Score (8, 16, 2):\n",
      "0.34828756979048625\n",
      "0.2250684374690224\n",
      "-------\n"
     ]
    }
   ],
   "source": [
    "for dep in depths:\n",
    "    for lfs in min_leafs:\n",
    "        runTree(dep, lfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Conclusion\n",
    "\n",
    "Unlike the rest, the Decision Tree model does seem to surpass the simple Linear Regression model (see \"Airbnb NYC Data Exploration\" notebook for details), which had scored 25.6% (training) and 20.2% (testing).\n",
    "\n",
    "Based on the tests, seems there is a maximum point where testing error is minimized. Also notable is the fact that the training & testing score seem to be inversely correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(criterion='mse', max_depth=8, min_samples_leaf=16, min_samples_split=2)\n",
    "tree_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict testing data\n",
    "pred_train = tree_reg.predict(X_train)\n",
    "pred_test = tree_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Manhattan---------\n",
      "44.15\n",
      "44.15\n",
      "44.15\n",
      "44.15\n",
      "\n",
      "--------Brooklyn---------\n",
      "30.37\n",
      "30.37\n",
      "30.37\n",
      "\n",
      "--------Queens---------\n",
      "30.37\n",
      "30.37\n"
     ]
    }
   ],
   "source": [
    "# Import prediction input\n",
    "df_nei_Manhattan_EV = pd.read_csv('./data/input/pred_input_Manhattan_EV.csv')\n",
    "df_nei_Manhattan_HA = pd.read_csv('./data/input/pred_input_Manhattan_HA.csv')\n",
    "df_nei_Manhattan_HK = pd.read_csv('./data/input/pred_input_Manhattan_HK.csv')\n",
    "df_nei_Manhattan_UWS = pd.read_csv('./data/input/pred_input_Manhattan_UWS.csv')\n",
    "\n",
    "df_nei_Brooklyn_BS = pd.read_csv('./data/input/pred_input_Brooklyn_BS.csv')\n",
    "df_nei_Brooklyn_BU = pd.read_csv('./data/input/pred_input_Brooklyn_BU.csv')\n",
    "df_nei_Brooklyn_WI = pd.read_csv('./data/input/pred_input_Brooklyn_WI.csv')\n",
    "\n",
    "df_nei_Queens_AS = pd.read_csv('./data/input/pred_input_Queens_AS.csv')\n",
    "df_nei_Queens_LI = pd.read_csv('./data/input/pred_input_Queens_LI.csv')\n",
    "\n",
    "avgRev_Manhattan_EV = round(tree_reg.predict(df_nei_Manhattan_EV)[0],2)\n",
    "avgRev_Manhattan_HA = round(tree_reg.predict(df_nei_Manhattan_HA)[0],2)\n",
    "avgRev_Manhattan_HK = round(tree_reg.predict(df_nei_Manhattan_HK)[0],2)\n",
    "avgRev_Manhattan_UWS = round(tree_reg.predict(df_nei_Manhattan_UWS)[0],2)\n",
    "\n",
    "avgRev_Brooklyn_BS = round(tree_reg.predict(df_nei_Brooklyn_BS)[0],2)\n",
    "avgRev_Brooklyn_BU = round(tree_reg.predict(df_nei_Brooklyn_BU)[0],2)\n",
    "avgRev_Brooklyn_WI = round(tree_reg.predict(df_nei_Brooklyn_WI)[0],2)\n",
    "\n",
    "avgRev_Queens_AS = round(tree_reg.predict(df_nei_Queens_AS)[0],2)\n",
    "avgRev_Queens_LI = round(tree_reg.predict(df_nei_Queens_LI)[0],2)\n",
    "\n",
    "print(\"--------Manhattan---------\")\n",
    "print(avgRev_Manhattan_EV)\n",
    "print(avgRev_Manhattan_HA)\n",
    "print(avgRev_Manhattan_HK)\n",
    "print(avgRev_Manhattan_UWS)\n",
    "print(\"\")\n",
    "print(\"--------Brooklyn---------\")\n",
    "print(avgRev_Brooklyn_BS)\n",
    "print(avgRev_Brooklyn_BU)\n",
    "print(avgRev_Brooklyn_WI)\n",
    "print(\"\")\n",
    "print(\"--------Queens---------\")\n",
    "print(avgRev_Queens_AS)\n",
    "print(avgRev_Queens_LI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.15\n",
      "44.15\n",
      "44.15\n"
     ]
    }
   ],
   "source": [
    "# Import prediction input\n",
    "df_nei_1_1 = pd.read_csv('./data/input/pred_input_Manhattan_EV.csv')\n",
    "df_nei_2_2 = pd.read_csv('./data/input/pred_input_Manhattan_EV_2bed_2_bath.csv')\n",
    "df_nei_2_1 = pd.read_csv('./data/input/pred_input_Manhattan_EV_2bed_1_bath.csv')\n",
    "\n",
    "avgRev_1_1 = tree_reg.predict(df_nei_1_1)[0]\n",
    "avgRev_2_2 = tree_reg.predict(df_nei_2_2)[0]\n",
    "avgRev_2_1 = tree_reg.predict(df_nei_2_1)[0]\n",
    "\n",
    "print(round(avgRev_1_1,2))\n",
    "print(round(avgRev_2_2,2))\n",
    "print(round(avgRev_2_1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Based on these parameters, seems like the best scoring model (Decision Trees) was a bit too generalized, making the same prediction for variations (e.g. 1 bedroom vs 2 bedroom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
